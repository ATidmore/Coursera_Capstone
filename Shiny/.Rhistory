predict(q3_fit, newdata = q6_x, interval = "prediction")
q6_lm <- lm(mpg ~ wt/2, data=mtcars)
q6_x <- data.frame(wt = 2000/1000)
predict(q6_lm, newdata = q6_x, interval = "prediction")
q6_lm <- lm(mpg ~ wt/2, data=mtcars)
q6_x <- data.frame(wt = 2000/1000)
predict(q6_lm, newdata = q6_x, interval = "prediction")
q6_lm <- lm(mpg ~ wt/2, data=mtcars)
q6_lm <- lm(mpg ~ I(wt/2), data=mtcars)
q6_x <- data.frame(wt = 2000/1000)
predict(q6_lm, newdata = q6_x, interval = "prediction")
View(q6_x)
q3_fit
q6_lm <- lm(mpg ~ I(wt - mean(wt), data = mtcars))
q6_lm <- lm(mpg ~ I(wt - mean(wt)), data = mtcars)
summary(q6_lm)
rm(q6_lm)
q6_x <- data.frame(wt = mean(mtcars$wt))
q6_ci <- predict(q3_fit, newdata = q6_x, interval = "confidence")
q6_ci
2*q6_ci
q6_ci/2
predict(q3_fit, newdata = q3_x, interval = "confidence")
str(summary(q3_fit))
summary(q3_fit)
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
summary(lm(y ~ x))
fit2 <- lm(y ~ I(x / 2))
tbl2 <- summary(fit2)$coefficients
mean <- tbl2[2,1]
se <- tbl2[2,2]
df <- fit2$df
#Two sides T-Tests
mean + c(-1,1) * qt(0.975, df=df) * se
# -12.97262  -8.40527
fitRes <- q3_fit$residuals ^ 2
fitIntercept <- lm(mpg ~ 1, mtcars)
fitInterceptRes <- fitIntercept$residuals ^ 2
sum(fitRes) /sum(fitInterceptRes) # 0.2471672
n <- 100;
x <- rnorm(n)
x2 <- rnorm(n)
x3 <- rnorm(n)
y <- 1 + x + x2 + x3 + rnorm(n, sd = .1) # <- error
ey <- resid(lm(y ~ x2 + x3))
ex <- resid(lm(x ~ x2 + x3))
sum(ey * ex) / sum(ex ^ 2)
coef(lm(y ~ x + x2 + x3))
lm(ey ~ ex  - 1)
coef(lm(y ~ x + x2 + x3))
me.price <- c(225,210,200,190,190,180,180,180,175,175)
ma.price <- c(50,60,60,60,60,60,60,65,65,65)
length(me.price)
length(ma.price)
me.rating <- c(89,88,75,69,87,78,79.89,62,78)
length(me.ra)
length(me.rating)
me.rating <- c(89,88,75,69,87,78,79,89,62,78)
ma.rating <- c(65,82,88,92,93,93,96,79,84,85)
boxplot(me.rating, ma.rating)
anova(me.rating, ma.rating)
?t.test
t.test(me.rating, ma.rating, alternative = "two.sided")
t.test(me.rating, ma.rating)
t.test(me.rating, ma.rating, alternative = "greater")
require(MASS)
?shuttle
data("shuttle")
head(shuttle)
unique(shuttle$use)
glm(use ~ wind, family = "binomial")
?glm
glm(use ~ wind, data = shuttle, family = "binomial")
glm(use ~ factor(wind), data = shuttle, family = "binomial")
glm(use ~ factor(wind)-1, data = shuttle, family = "binomial")
shuttle2<-shuttle
shuttle2$use2<-as.numeric(shuttle2$use=='auto')
head(shuttle2)
glm(use2 ~ factor(wind), data = shuttle2, family = "binomial")
unique(shuttle2$wind)
glm(use2 ~ factor(wind)-1, data = shuttle2, family = "binomial")
glm(use2 ~ factor(wind), data = shuttle2, family = "binomial")
fit <- glm(use2 ~ factor(wind), data = shuttle2, family = "binomial")
summary(fit)$coef
shuttle2$wind2<-as.numeric(shuttle2$wind=='head')
fit <- glm(use2 ~ factor(wind), data = shuttle2, family = "binomial")
summary(fit)$coef
fit <- glm(use2 ~ factor(wind)-1, data = shuttle2, family = "binomial")
summary(fit)$coef
exp(coef(fit))
fit
exp(coef(fit))
1.286 / 1.327
fit_q2 <- glm(use2 ~ factor(wind) + factor(magn) -1, data = shuttle2, family = "binomial")
exp(coef(fit_q2))
1.4384/1.4852 #head wind / tail
data("InsectSprays")
str(InsectSprays)
fit.q4 <- glm(count ~ spray)
fit.q4 <- glm(count ~ spray, data = InsectSprays, family = "poisson")
summary(fit.q4)
fit.q4 <- glm(count ~ factor(spray), data = InsectSprays, family = "poisson")
summary(fit.q4)
fit.q4 <- glm(count ~ spray-11, data = InsectSprays, family = "poisson")
fit.q4 <- glm(count ~ spray-1, data = InsectSprays, family = "poisson")
summary(fit.q4)
2.67415/2.73003
exp(coef(fit.q4))
14.5/15.33
y <- c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
x <- -5:5
knot <- c(0)
splineTerms <- sapply(knot, function(knot) (x > knot) * (x - knot))
xMat <- cbind(1, x, splineTerms)
fit.q6 <- lm(y ~ xMat-1)
summary(fit.q6)
xMat
plot(fit.16)
plot(fit.q6)
yhat <- predict(fit.q6)
summary(fit.q6)$coef
(yhat[10]-yhat[6])/4
data(nuclear)
require(datasets)
data(nuclear)
?"datasets"
library(help = "datasets")
install.packages("RServe")
install.packages("Rserve")
?rnorm
x <- rnorm(500, mean = 2419, sd = 771)
hist(x)
density(x)
plot(density(x))
x <- rnorm(5000, mean = 2419, sd = 771)
plot(density(x))
install.packages("RODBC")
library(RODBC)
odbcConnect("Local-ATSand")
conn <- odbcConnect("Local-ATSand")
odbcClose(conn)
conn <- odbcConnect("Local-ATSand")
sqlQuery(conn, "SELECT count(*) from POS_FINAL")
x <- sqlQuery(conn, "SELECT count(*) from POS_FINAL")
x
odbcClose(conn)
data(AlzheimerDisease)
install.packages("caret")
install.packages("AppliedPredictiveModeling")
library(datasets)
data(AlzheimerDisease)
data(AlzheimerDisease)
require(caret)
require(AppliedPredictiveModeling)
data(AlzheimerDisease)
data(concrete)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4, data(concrete))[[1]]
require(caret)
install.packages("caret")
require(caret)
data(concrete)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4, data(concrete))[[1]]
training = mixtures[ inTrain,]
inTrain <- createDataPartition(mixtures$CompressiveStrength, p = 3/4, data(concrete))[[1]]
source('~/Training/CourseraDataScience/7RegModels/Week2/quiz2.R', echo=TRUE)
detach("AlzheimerDisease")
data(concrete)
set.seed(1000)
inTrain <- createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
head(training)
histogram(Superplasticizer, concrete)
histogram(Superplasticizer, concrete)
histogram(Superplasticizer, data= concrete)
histogram(Superplasticizer)
histogram(concrete$Superplasticizer)
summary(training)
histogram(log(concrete$Superplasticizer+1))
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
head(training)
train.pca <- training[["IL", exact = FALSE]]
summary(train.pca)
train.pca <- training[,grep("IL")]
train.pca <- training[ ,grepl("IL", names(training))]
summary(train.pca)
train.pca <- training[ ,grepl("^IL", names(training))]
summary(train.pca)
preProc <- preProcess(train.pca, method = "pca")
summary(preProc)
preProcess(train.pca, method = "pca")
?preProcess
preProcess(train.pca, method = "pca", thresh = .8)
q4train.pca <- training[ ,c(grepl("^IL", names(training)), "diagnosis"]
q4train.pca <- training[ ,c(grepl("^IL", names(training)), "diagnosis")]
q4train.pca <- training[ ,grepl("^IL|diagnosis", names(training))]
summary(q4train.pca)
q4modelfit.pca <- train(q4train.pca$diagnosis ~ . ,method="glm", preProcess="pca", data = q4train.pca)
install.packages("e1071")
require(e1071)
q4modelfit.pca <- train(q4train.pca$diagnosis ~ . ,method="glm", preProcess="pca", data = q4train.pca)
summary(q4modelfit.pca)
q4modelfit <- train(q4train.pca$diagnosis ~ . ,method="glm", data = q4train.pca)
q4modelfit.pca <- train(q4train.pca$diagnosis ~ . ,method="glm", preProcess="pca", thresh = 0.8, data = q4train.pca)
q4modelfit.pca <- train(q4train.pca$diagnosis ~ . ,method="glm", preProcess="pca", thresh = 0.8, data = q4train.pca)
?train
q4modelfit.pca <- train(q4train.pca$diagnosis ~ . ,method="glm", preProcess="pca", data = q4train.pca)
q4modelfit <- train(q4train.pca$diagnosis ~ . ,method="glm", data = q4train.pca)
q4modelfit.pca
q4modelfit.pca$Accuracy
q4modelfit.pca[1]
q4modelfit.pca["Accuracy"]
?confusionMatrix
confusionMatrix(q4modelfit.pca)
c(q4modelfit, q4modelfit.pca)
q4modelfit
q4modelfit.pca
version
exit
exit()
install.package("ElemStatLearn")
install.packages("ElemStatLearn")
install.packages("pgmm")
library(AppliedPredictiveModeling)
library(caret)
library(ElemStatLearn)
library(pgmm)
library(rpart)
q1.data <- data(segmentationOriginal)
head(q1.data)
q1.data
rm(q1.data)
head(segmentationOriginal)
data <- segmentationOriginal
q1.data <- data
rm(data)
rm(q1.data)
str(segmentationOriginal)
table(segmentationOriginal$Case)
?createDataPartition
inTrain <- createDataPartition(y=segmentationOriginal$Class, p = 0.5, list=FALSE)
training <- segmentationOriginal[inTrain]
testing <- segmentationOriginal[-inTrain]
dim(training)
inTrain <- createDataPartition(y=segmentationOriginal$Case, p = 0.5, list=FALSE)
training <- segmentationOriginal[inTrain]
testing <- segmentationOriginal[-inTrain]
dim(training)
dim(testing)
testing
str(training)
training <- segmentationOriginal[inTrain ,]
testing <- segmentationOriginal[-inTrain ,]
str(segmentationOriginal)
q1.model <- train(Class ~ ., method="rpart", data=training)
summary(q1.model)
set.seed(125)
q1.model <- train(Class ~ ., method="rpart", data=training)
set.seed(125)
inTrain <- data$Case == "Train"
training <- segmentationOriginal[inTrain ,]
testing <- segmentationOriginal[-inTrain ,]
q1.model <- train(Class ~ ., method="rpart", data=training)
q1.model$finalModel
plot(cartModel$finalModel, uniform=T)
plot(q1.model$finalModel, uniform=T)
text(cartModel$finalModel, cex=0.8)
text(q1.model$finalModel, cex=0.8)
q1.model$finalModel
library(rattle)
install.packages("rattle")
library(rattle)
library(rattle)
fancyRpartPlot(q1.model$finalModel)
library(rpart)
library(rattle)
fancyRpartPlot(q1.model$finalModel)
library(pgmm)
data(olive)
q3.data <- olive
str(q3.data)
olive <- olive[,-1]
q3.model <- train(Area ~ . ,data = q3.data, method = "rpart2")
q3.newdata <- as.data.frame(t(colMeans(olive)))
q3.model$finalModel
fancyRpartPlot(q1.model$finalModel)
update.packages("rpart")
update.packages("rpart")
update.packages("rattle")
library(rpart)
library(rattle)
fancyRpartPlot(q1.model$finalModel)
q3.model$finalModel
q3.predict <- predict(q3.model, q3.newdata)
q3.newdata <- as.data.frame(t(colMeans(olive)))
q3.predict <- predict(q3.model, q3.newdata)
q3.model <- train(Area ~ . ,data = olive, method = "rpart2")
q3.newdata <- as.data.frame(t(colMeans(olive)))
q3.predict <- predict(q3.model, q3.newdata)
q3.predict
summary(olive$Area)
dim(olive$Area)
table(olive$Area)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
str(train)
summary(TrainSA)
summary(trainSA)
q4.model <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data = trainSA, method = "glm")
q4.model <- train(as.factor(chd) ~ age + alcohol + obesity + tobacco + typea + ldl, data = trainSA, method = "glm")
summary(q4.model)
missClass <- function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
predictTrain <- predict(q4.model, trainSA)
predictTest <- predict(q4.model, testSA)
# Training Set Misclassification rate
missClass(trainSA$chd, predictTrain) # 0.2727273
# Test Set Misclassification rate
missClass(testSA$chd, predictTest) # 0.3116883
q4.model <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data = trainSA, method = "glm", family = "binomial")
missClass <- function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
predictTrain <- predict(q4.model, trainSA)
predictTest <- predict(q4.model, testSA)
missClass(trainSA$chd, predictTrain) # 0.2727273
missClass(testSA$chd, predictTest) # 0.3116883
head(predictTrain)
missClass(testSA$chd, predictTest)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
summary(vowel.train)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
q5.train <- train(y ~ . , data = vowel.train, method = "rf")
q5.train <- train(y ~ . , data = vowel.train, method = "rf")
varImp(q5.train)
library(RODBC)
conn <- odbcConnect("NZSQL") --Specify DSN entry
conn <- odbcConnect("NZSQL")
and upper(ltrim(rtrim(POS.POS_VEH_SERIES))) = upper(ltrim(rtrim(CTGRY.SERIES)))")
data <- sqlQuery(conn, "select 1")
data
odbcClose(conn)
library(shiny)
runapp()
runApp()
x <- x + 1
install.packages("devtools")
require(devtools)
install_github('rCharts', 'ramnathv')
install.packages("RCurl")
install.packages("RCurl")
require(RCurl)
install_github('ramnathv/rCharts'
install_github('ramnathv/rCharts')
install_github('ramnathv/rCharts')
require(devtools)
install_github('ramnathv/rCharts')
require(rCharts)
install.packages("googleVis")
suppressPackageStartupMessages(library(googleVis))
require(Rtools)
print(.libPaths())
library(Rtools)
Sys.getenv("R_LIBS_USER")
Sys.getenv('PATH')
require(devtools)
install.packages("slidify")
install_github('slidify', 'ramnathv')
install_github('ramnathv/slidify')
remove.packages("stringi")
data("occupationalStatus")
Diag <- as.factor(diag(1:8))
Rscore <- scale(as.numeric(row(occupationalStatus)), scale = FALSE)
Cscore <- scale(as.numeric(col(occupationalStatus)), scale = FALSE)
modUnif <- glm(Freq ~ origin + destination + Diag + Rscore:Cscore,
family = poisson, data = occupationalStatus)
summary(modUnif)
plot(modUnif) # 4 plots, with warning about  h_ii ~= 1
data("austres")
str(austres)
summary(austres)
data("BJsales")
data("BJsales")
plot(BJsales)
plot(BJsales.lead)
plot(BJsales)
data("sunspot.month")
plot(sunspot.month)
plot (sunspot.month,
main="sunspot.month & sunspots [package'datasets']", col=2)
lines(sunspots) # -> faint differences where they overlap
library(ggplot2)
?"ggplot2"
?"ggplot2-package"
?"ggplot2-package"
install.packages("tm")
?tm
require(string
)
require(stringdist)
?lv
stringdist("ANTS", "GNU", method = "lv")
stringsim("ANTS", "GNU", method = "lv")
install.packages("RecordLinkage")
require(stringdist)
stringdist("intention", "execution", method = "lv")
stringdist("intention", "execution", method = "lv")?
?"stringdist"
stringdistmatrix("abc", "xa" ,method = "v")
stringdistmatrix("abc", "xa" ,method = "lv")
stringdistmatrix("intention", "execution" ,method = "lv")
stringdist(intention, execution, method = "lv")
require(RWeka)
Sys.getenv()
require(quantmod)
?getSymbols
getSymbols("AAPL")
str(AAPL)
head(AAPL)
getSymbols("AAPL", from = as.Date("01/01/2010", format = "%m/%d%/%y"))
from.date <- as.Date("01/01/2010", format = "%m/%d%/%y")
from.date
from.date <- as.Date("01/01/10", format = "%m/%d%/%y")
from.date
as.Date("01/01/10", format = "%m/%d%/%y")
?as.Date
from.date <- as.Date("01/01/10", "%m/%d%/%y")
from.date <- as.Date("01/01/2010", "%m/%d%/%Y")
as.Date("01/01/2010", "%m/%d%/%Y")
as.Date("01/01/2010")
from.date <- as.Date("01/01/2010", "%m/%d/%y")
from.date
from.date <- as.Date("01/01/2010", "%m/%d/%Y")
from.date
getSymbols("AAPL", from = from.date)
decompose(AAPL)
?to.monthly
aapl.wkly <- to.weekly(aapl)
aapl.wkly <- to.weekly(AAPL)
decompose(aapl.wkly)
aapl.monthly <- to.monthly(AAPL)
decompose(aapl.monthly)
ts(aapl.monthly)
decompose(appl.monthyl)
decompose(appl.monthly)
decompose(aapl.monthly)
?decompose
?ts
aapl.monthly.ts <- ts(aapl.monthly)
decompose(aapl.monthly.ts)
head(aapl.monthly.ts)
?ts
aapl.monthly.ts <- ts(aapl.monthly, frequency = 30)
decompose(aapl.monthly.ts)
head(aapl.monthly.ts)
plot(decompose(aapl.monthly.ts))
nrows(aapl.monthly.ts)
nrow(aapl.monthly.ts)
rnorm(n = 10, mean = 3.5)
runif(n = 10)
?runif
rnorm(n = 10, mean = 3.5)
sum(rnorm(n = 10, mean = 3.5))
sum(rnorm(n = 10, mean = 3.5))
sum(rnorm(n = 10, mean = 3.5))
sum(rnorm(n = 10, mean = 3.5))
sum(rnorm(n = 10, mean = 3.5))
sum(rnorm(n = 10, mean = 3.5))
sum(rnorm(n = 10, mean = 3.5))
sum(rnorm(n = 16, mean = 3.5))
sum(rnorm(n = 16, mean = 3.5))
sum(rnorm(n = 16, mean = 3.5))
sum(rnorm(n = 16, mean = 3.5))
memory.limit()
getwd()
setwd("~/Training/CourseraDataScience/CAPSTONE/Shiny")
runApp()
library(shiny)
runApp()
getwd()
setwd("./data")
load(file = "DFM.Pred.RData")
load(file = "Prediction.RData")
runApp()
setwd("../")
runApp()
shiny::runApp()
getwd()
shiny::runApp()
shiny::runApp()
getwd()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
